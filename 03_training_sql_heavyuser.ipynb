{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Training: SQL (Heavy-users) üí™\n",
                "Welcome to the training notebook on using SQL.\n",
                "\n",
                "\n",
                "This notebook is pitched at heavy users who perform data management roles to store objects permanently in SQL. \n",
                "\n",
                "They will have **READ-WRITE** or higher access to the database.\n",
                "\n",
                "![SQL girl meme](https://live.staticflickr.com/65535/49198404911_55085b0307_z.jpg \"SQL girl meme\") \n",
                "\n",
                "# What will this session cover? üëÇ\n",
                "This session will show you how to do the following things in SQL:\n",
                "1. Dynamic SQL querying\n",
                "1. What makes a well-governed database?\n",
                "1. Creating and updating tables\n",
                "1. Importing data into SQL\n",
                "1. Indexing columns to improve querying speeds\n",
                "1. Adding constraints to columns to restrict entries that can go inside it\n",
                "1. Using stored procedures and functions to do more bespoke operations\n",
                "1. Database triggers for tracking activity\n",
                "1. Version-controlling databases"
            ],
            "metadata": {
                "azdata_cell_guid": "a1525136-1fc3-4c51-85b0-ac160d7ff3ff"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- set database to use\r\n",
                "USE [AdventureWorks];"
            ],
            "metadata": {
                "azdata_cell_guid": "39a29ac5-eaa2-4825-87f9-a27728d31183",
                "tags": []
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 1. Dynamic SQL querying ü§∏‚Äç‚ôÇÔ∏è\r\n",
                "This is essentially SQL code that writes SQL code. It's particularly useful when you want to parameterise your SQL statements with an input variable. \r\n",
                "\r\n",
                "To be able to employ dynamic SQL querying, you'll need to know how to:\r\n",
                "1. Create a variable in SQL and assign it a value\r\n",
                "1. Create a SQL query which takes the variable you created\r\n",
                "1. Execute the SQL query\r\n",
                "\r\n",
                "The core idea behind dynamic SQL querying lies in being able to write your query as a string/varchar/text, and then execute/run the text as if it is a SQL query.\r\n",
                "\r\n",
                "> **USER STORY:** *As a lazy-ass, punk-ass, funk-ass SQL version of NAS, I want to quickly run a SQL statement to quickly count all the number of rows in several tables in my database rather than write the same* `SELECT COUNT(*) FROM <*table_name*>` *statement several times but with different table names, so I can get back to making my new coding mixtape.* üé§üéß\r\n",
                "\r\n",
                "The code below is a rubbish example of the power of dynamic SQL querying. A better illustration of when and why you woukd prefer to use dynamic SQL querying can be found in the exercises in *(4.)*.\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "71db0edd-4215-4b60-b85e-590261e4b8f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create and set variable/parameters\r\n",
                "DECLARE @name_schema AS NVARCHAR(25) = 'Production'\r\n",
                "DECLARE @name_table AS NVARCHAR(50) = 'Location'\r\n",
                "\r\n",
                "-- write dynamic SQL as string/text\r\n",
                "DECLARE @query AS NVARCHAR(MAX) = \r\n",
                "'\r\n",
                "    SELECT COUNT(*)\r\n",
                "    FROM [' + @name_schema + '].[' + @name_table + '];\r\n",
                "' \r\n",
                "\r\n",
                "-- print query to see what SQL is written\r\n",
                "PRINT @query\r\n",
                "\r\n",
                "-- excute dynamic SQL being written as string/text\r\n",
                "EXEC sp_executesql @query"
            ],
            "metadata": {
                "azdata_cell_guid": "fd3e44fa-e8d0-45ae-98cb-22cf1dbd922d"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üê¥ EXERCISE: Dynamic SQL querying #1\r\n",
                "**Question:** Is there an even more efficient way to perform the same task in (1.) without having to use dynamic SQL querying?\r\n",
                "\r\n",
                "**Hint:** Consider using System Tables belonging to the `[sys]` database.\r\n",
                "\r\n",
                "**Note:** This exercise introduces you to some very useful tables that exist in the background which will be extremely useful for data management tasks. You may also explore the tables in the `[INFORMATION_SCHEMA]` database. Lastly, it shows that dynamic SQL is not always the best option. "
            ],
            "metadata": {
                "azdata_cell_guid": "5817afee-8c6d-49d0-b967-05dd245168f3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "85468e8e-cf2d-4313-bda4-65e96a148488"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 2. What makes a well-governed database? üì£\r\n",
                "The attitude to storing data and code in SQL should be different to storing data and code in a folder. As a database administrator/architect/manager, your role is to effectively govern the storage and access of data so that it can be intuitively found, easily accessed and fluidly recycled/reused.\r\n",
                "\r\n",
                "This means that what is held in SQL should meet the following criteria:\r\n",
                "\r\n",
                "- [ ] Be **C**onsistent - all naming should follow a style-guide so that users of the databse can navigate easily to where they want to go.\r\n",
                "    - Within this, you also want to explicitly and distinctly separate out the various objects by giving a specific naming to tables, Views, stored procedures etc.\r\n",
                "    - Such a style-guide is available [here](https://github.com/avisionh/Training-SQL/wiki/Style-Guide:-T-SQL)\r\n",
                "- [ ] Be **O**pen - in a database that's accessible to a wide range of people, create with their perspective in mind. \r\n",
                "\r\n",
                "> **Example I:**\r\n",
                "> - `[usr].[Y14_15_Student_Fix_Core]`\r\n",
                "> - `[usr].[Y14_15_Student_Fix_Fix_Core]`\r\n",
                "> - `[usr].[Y14_15_Student_Fix_Old_Core]`\r\n",
                "> - This is horrendous! What the heck does *Fix_Fix*, *Fix_Old* mean? Blimey!!!\r\n",
                "\r\n",
                "- [ ] Be **P**ersistent - temporary or test objects should be wiped. Only objects that are useful should be there.\r\n",
                "    - If a temporary or test object is needed later, consider if it can be made into a permanent table, a temp table or stored in a database specifically for experimentation.\r\n",
                "\r\n",
                "> **Example II:** `[dbo].[SLC_extract_140917_temp]` is horrific! Having several of them is even worse.\r\n",
                "\r\n",
                "- [ ] Be **O**rderly - make use of naming to order objects appropriately\r\n",
                "\r\n",
                "> **Example III:** Should you organise the below four tables by collection or year?\r\n",
                "> - `[usr].[Y14_15_Staff_Core]`\r\n",
                "> - `[usr].[Y14_15_Student_Core]`\r\n",
                "> - `[usr].[Y15_15_Staff_Core]`\r\n",
                "> - `[usr].[Y15_16_Student_Core]` \r\n",
                "\r\n",
                "\r\n",
                "- [ ] Be **U**nderstanding - you have to balance out each team's considerations and ensure they all agree to a common framework/standard\r\n",
                "    - How do you tackle the issue presented in *Example I*?\r\n",
                "- [ ] Be **T**hematic - consider what is themed and bring them together\r\n",
                "    - Do you have many tables that do lookups? Why not put them together into a general structure?\r\n",
                "\r\n",
                "If you like pneumonics, this means you should be a **COP OUT**.\r\n",
                "\r\n",
                "![SQL roll safe meme](https://i.imgur.com/Hya1F1s.gif \"SQL roll safe meme\") \r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "3d1c9f51-2234-4b2d-b85b-9ca073c91df9"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3. Creating and updating tables ‚ôªÔ∏è\r\n",
                "When deciding that **temporary tables** are unsuitable for your usage because you want to increase access to the data explicitly for more people or people will be building off your query to view the **CTE**, then creating and updating a table to store permanently in a SQL database is appropriate. \r\n",
                "\r\n",
                "When creating a table, you may want to store it in **tidy data format** (covered in *Training: SQL (Medium-users))*) so the same data but in a different version or time can be imported to this, meaning you are **updating** the ewly-created table.\r\n",
                "\r\n",
                "To create a table, you need to know a few things upfront such as the columns it will contain, their data types and version. \r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "892ceb54-a199-4f2c-94bd-4e403c49eb53"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "``` SQL\r\n",
                "-- template: create table query\r\n",
                "CREATE TABLE [<schema_name>].[<table_name>] (\r\n",
                "    [Column_1] <datatype>\r\n",
                "    ,[Column_2] <datatype>\r\n",
                "    ,...\r\n",
                ");\r\n",
                "\r\n",
                "-- template: update table \r\n",
                "UPDATE [<schema_name>].[<table_name>]\r\n",
                "SET [column_n] = <new_value>\r\n",
                "WHERE [column_j] = <filter_value>;\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "4ef853ab-8681-4308-bddf-29c10b60dd2e"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 4. Importing data into SQL üè≥Ô∏è‚Äçüåà\r\n",
                "After deciding that you want to store the data in a table on SQL, and having creatied the tables, you next job is to actually import the data into the table. There are several methods.\r\n",
                "1. **SQL Server Import Wizard:** Good for relatively quick, one-time imports of datasets. Bad for multiple table imports of the same datasets.\r\n",
                "1. **Powershell:** Fantastic for bulk-inserting multiple datasets. Bad if you don't want to learn another coding/scripting language.\r\n",
                "1. **Bulk load via SQL code:** Good for importing multiple datasets directly into SQL. Bad if you don't have high permission rights. \r\n",
                "\r\n",
                "```\r\n",
                "-- table to loop through file names \r\n",
                "CREATE TABLE [AdminDetails].[SourceData]\r\n",
                "(\r\n",
                "    [PathFile] NVARCHAR(MAX)\r\n",
                "    ,[NameFile] NVARCHAR(MAX)\r\n",
                ")\r\n",
                "\r\n",
                "-- declare variables\r\n",
                "DECLARE @filename AS NVARCHAR(250)\r\n",
                "    ,@filepath AS NVARCHAR(MAX)\r\n",
                "    ,@codesql AS NVARCHAR(MAX)\r\n",
                "    ,@command AS NVARCHAR(1000)\r\n",
                "\r\n",
                "-- get list of files to process\r\n",
                "SET @filepath = 'C:\\Temp\\'\r\n",
                "SET @command = 'dir ' + @path + '*.csv /b'\r\n",
                "\r\n",
                "INSERT INTO [AdminDetails].[SourceData]([NameFile])\r\n",
                "EXEC Master..xp_cmdShell @command\r\n",
                "\r\n",
                "UPDATE [AdminDetails].[SourceData] \r\n",
                "SET [PathFile] = @filepath \r\n",
                "WHERE [PathFile] IS NULL\r\n",
                "\r\n",
                "-- cursor loop\r\n",
                "DECLARE c1 CURSOR FOR\r\n",
                "    SELECT [PathFile]\r\n",
                "        ,[NameFile]\r\n",
                "    FROM [AdminDetails].[SourceData]\r\n",
                "    WHERE [PathFile] LIKE '%.csv%'\r\n",
                "\r\n",
                "OPEN c1\r\n",
                "\r\n",
                "FETCH NEXT FROM c1 INTO @filepath, @filename\r\n",
                "WHILE @@fetch_status != -1\r\n",
                "    BEGIN\r\n",
                "        -- bulk insert won't take a variable name, so make a parameter for SQL to read and execute\r\n",
                "        SET @codesql = \r\n",
                "        '\r\n",
                "            BULK INSERT [<schema_name>].[<table_name>]\r\n",
                "            FROM ''' + @filepath + @filename + ''' ' + '\r\n",
                "            WITH(\r\n",
                "                FIELDTERMINATOR = '',''\r\n",
                "                ,ROWTERMINATOR = ''\\n''\r\n",
                "                ,FIRSTROW = 2\r\n",
                "            ) '\r\n",
                "PRINT @codesql\r\n",
                "EXEC (@codesql)\r\n",
                "```\r\n",
                "\r\n",
                "*Code slightly adapted from [here](https://stackoverflow.com/questions/16076309/import-multiple-csv-files-to-sql-server-from-a-folder)*\r\n",
                "\r\n",
                "1. **Direct insertion via SQL code:** Good for realtively quick, one time imports of rows. Bad for anything outside of this.\r\n",
                "```\r\n",
                "INSERT INTO [<schema_name>].[<table_name>] (\r\n",
                "    [column_name_1]\r\n",
                "    ,[column_Name_2]\r\n",
                "    , ...\r\n",
                "    , [column_name_n]\r\n",
                ")\r\n",
                "VALUES\r\n",
                "    (row_1_value_1, row_1_value_2, ..., row_1_value_n)\r\n",
                "    ,(row_2_value_1, row_2_value_2, ..., row_2_value_n)\r\n",
                "    ,...\r\n",
                "    ,(row_k_value_1, row_k_value_2, ..., row_k_value_n)\r\n",
                "```\r\n",
                "1. **SSIS Package:** Good fdoing more bespoke things like not inserting duplicate rows. Bad for bulk importing multiple datasets.\r\n",
                "1. **R:** Good as this is a relatively easy programming language to learn. Bad if you are trying to import a large amount of data.\r\n",
                "\r\n",
                "We define *large* in point (4.) with regards to the size of the ***data being imported into SQL being larger than the amount of RAM your computer has.*** This is because importing data into SQL from R requires importing the data into your R session first, then moving it across into SQL. As R stores data on the computers RAM for fast retrieval (relative to storage on a hard disk), then if the data was larger than the RAM, this would be a very slow process. "
            ],
            "metadata": {
                "azdata_cell_guid": "8175a594-dcdf-412c-976e-5b9f4f83015d"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üçæ EXERCISE: Inserting data into tables\r\n",
                "In the below code, we have created a table for you to work with.\r\n",
                "```\r\n",
                "CREATE TABLE [Person].[ProductPreference]\r\n",
                "(\r\n",
                "   [StaffId] INT IDENTITY(1,1) PRIMARY KEY\r\n",
                "   ,[StaffUnit] NVARCHAR(25)\r\n",
                "   ,[BookFavourite] NVARCHAR(100)\r\n",
                "   ,[BookAuthor] NVARCHAR(100)\r\n",
                "   ,[SongFavourite] NVARCHAR(100)\r\n",
                "   ,[SongArtist] NVARCHAR(100)\r\n",
                "   ,[FilmFavourite] NVARCHAR(100)\r\n",
                "   ,[FilmDirector] NVARCHAR(100)\r\n",
                "   ,[DataTimeCreation] DATETIME DEFAULT(GETDATE()) \r\n",
                ")\r\n",
                "```\r\n",
                "**QUESTION:** Can you complete one row of this table with your preferences?\r\n",
                "\r\n",
                "**NOTE:** From the definitions of the `[StaffId]` and `[DateTimeCreation]` fields, there is no need for you to enter these yourselves. Do you know what they do?"
            ],
            "metadata": {
                "azdata_cell_guid": "a2320550-bb51-401e-8241-4c86513fa039"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "6c8aa963-2a40-44de-bb53-8ff86a7e9101"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üôÜ‚Äç‚ôÄÔ∏è EXERCISE: Thinking about objects in SQL\r\n",
                "**QUESTION:** Consider the following discussion questions below:\r\n",
                "1. Thinking about the `[StaffId]` column, do you know what it does? \r\n",
                "1. Why might the name of this column be inappropriate for what it actually does? \r\n",
                "1. Can you think of a way to improve this?"
            ],
            "metadata": {
                "azdata_cell_guid": "431a57ec-3242-4b73-961a-98cf030342d0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answers below"
            ],
            "metadata": {
                "azdata_cell_guid": "6a5f2ba3-3d62-485c-9831-a052ab6c4846"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ü§Ø EXERCISE: Dynamic unpivoting\r\n",
                "In actual fact, the table created above, `[Person].[ProductPreference]` is not in a tidy data form. As a database manager, this is a personal affront to you as you want to provide analysts with a formatted table of data that makes their jobs easier.\r\n",
                "\r\n",
                "**QUESTION:** Can you unpivot the `[Person].[ProductPreference]` table so that it is in **tidy data** format? Try to unpivot it without explicitly referncing the columns you want to unpivot to rows.\r\n",
                "\r\n",
                "**NOTE:** This exercise is designed to get you thinking about what makes a good, structured table in SQL that's helpful to the end-user, the analyst. It brings in concepts covered in *(1.)* and *(2.)*. It also shows you the power of dynamic querying."
            ],
            "metadata": {
                "azdata_cell_guid": "3c32707b-3704-451e-8100-e07705ea0e8f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "a23d7b2f-cc62-475d-ade9-207efe7798d4"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 5. Indexing columns to improve querying speeds üìó\r\n",
                "With really big tables, it makes sense to **index** their columns so that it is much more faster to query from them via filtering/joining or other SQL operations.\r\n",
                "\r\n",
                "**Column indexes/indices** are essentially a way of creating \"bookmarks\" in your data so that when you're filtering from it for instance, the SQL engine looks through the bookmarks and filters on them, rather than go into each entry, row-by-row, and filtering.\r\n",
                "\r\n",
                "They do slow down `UPDATE` and `INSERT` operations so you may want to drop **indexes** before performing these operations and then reapply the **indexes**.\r\n",
                "\r\n",
                "There are two types of **indexes**:\r\n",
                "- üì´ **Clustered:** Physically orders the data on the ~~hard~~ disk. This can make `ORDER BY` operations significantly faster.\r\n",
                "    + Only one can be created per table.\r\n",
                "    + Faster to read than non-clustered index as data is physically stored in an index order.\r\n",
                "    + Does not take additional memory to store.\r\n",
                "- üì¨ **Non-clustered:** Defines a \"logical\" order that does not match the physical order on the ~~hard~~ disk. This \"logical\" order is like a layer on top of a physical order, where a pointer is used.\r\n",
                "    + More than one can be created per table as they can be applied to columns.\r\n",
                "    + Data insertion/update is faster than clustered index. \r\n",
                "    + Needs additional memory to store.\r\n",
                "\r\n",
                "![Clustered image](https://i.stack.imgur.com/kFSWR.png \"Clustered image\")\r\n",
                "\r\n",
                "> **TIP:** Typically, **clustered indexes** are created on the most unique column or columns in your data, such as a unique identifier (also known in SQL parlance as the **primary key**).\r\n",
                ">> For the most part, we use **non-clustered indexes** on columns which we plan to filter by and join on and drop them before inserting or updating data in the tables.\r\n",
                "\r\n",
                "```\r\n",
                "-- template: create index\r\n",
                "CREATE NONCLUSTERED INDEX IX_<table_name>_<column_name>\r\n",
                "    ON [<schema_name>].[<table_name>] ([<column_name>])\r\n",
                "    -- enable faster index creation/rebuild times\r\n",
                "    -- without this, can dramaticall increase tempdb file sizes, which is bad!\r\n",
                "    WITH (SORT_IN_TEMPDB = ON);\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "927c8c32-d60e-49c0-8c32-15d22c9e0293"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "```\r\n",
                "-- template: drop multiple indexes, checking if they exist first\r\n",
                "IF EXISTS \r\n",
                "(\r\n",
                "    SELECT [name] FROM [sys].[indexes]\r\n",
                "    WHERE [name] IN (N'IX_<table_name>_<column_name_1>', 'IX_<table_name>_<column_name_2>', ...)\r\n",
                ") \r\n",
                "BEGIN\r\n",
                "    DROP INDEX IX_<table_name>_<column_name_1>\r\n",
                "        ON [<schema_name>].[<table_name>]\r\n",
                "    DROP INDEX IX_<table_name>_<column_name_2>\r\n",
                "         ON [<schema_name>].[<table_name>]\r\n",
                "    ...\r\n",
                "END\r\n",
                "\r\n",
                "-- need to specify what to do if these indexes don't exist\r\n",
                "-- otherwise SSIS package will throw error because won't know\r\n",
                "-- what to do if indexes don't exist\r\n",
                "ELSE \r\n",
                "BEGIN\r\n",
                "    WAITFOR DELAY '00:00:00'\r\n",
                "END;\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "bb2b848d-b1b6-44ad-954e-569ba13695ab"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 6. Adding constraints to columns üí∏\r\n",
                "Adding **constraints** to columns in you data ensures the integrity of possible values being entered into the table. They specify rules that data must adhere to in your tables.\r\n",
                "\r\n",
                "Specifically of interest is the **check constraint** which sets a specified list of values that the column can take, and any data being entered into the table that does not fulfill this pre-specified list of values cannot be imported until this is resolved.\r\n",
                "\r\n",
                "```\r\n",
                "-- template: create constraint on existing table\r\n",
                "ALTER TABLE [<schema_name>].[<table_name>]\r\n",
                "ADD CONSTRAINT CHK_<constraint_name> CHECK ([<column_integer>] > n AND [<column_string>] IN ('string_1', 'string_2', ...))\r\n",
                "```\r\n",
                "\r\n",
                "```\r\n",
                "-- template: drop constrain on existing table\r\n",
                "ALTER TABLE [<schema_name>].[<table_name>]\r\n",
                "DROP CHECK CHK_<constraint_name>\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "a908338a-776e-4e2a-b27e-205f2972fbcf"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üë• EXERCISE: Adding contraint to prevent rogue entries\r\n",
                "**QUESTION:** In the `[Person].[ProductPreference]` table, can you add a constraint on the `[FilmFavourite]` column to ensure that is must always be completed?"
            ],
            "metadata": {
                "azdata_cell_guid": "a2357ca4-d828-4940-b157-bf2302e67001"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "f55d59a2-7d25-4b96-8eb2-2977419c1ebb"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 7. Using stored procedures and functions üõ†üî¶\r\n",
                "**Stored procedures** and **functions** both execute a set of SQL instructions to return a result. However they are different in subtle ways.\r\n",
                "***\r\n",
                "## 7.i. Stored Procedures üóú\r\n",
                "A **Stored procedures** is a group of SQL statements stored in the database. They can be called from SQL, another **stored procedure**, the command line, or a different program such as R or Excel.\r\n",
                "\r\n",
                "For instructions on how to create **stored procedures** within SSMS, see the official documentation [here](https://docs.microsoft.com/en-us/sql/relational-databases/stored-procedures/create-a-stored-procedure?view=sql-server-ver15).\r\n",
                "\r\n",
                "Advantages | Disadvantages\r\n",
                "--- | --- |\r\n",
                "Can be set-up to run automatically on a schedule | Harder to version-control unless you use method in *(9.)*\r\n",
                "Can **resuse** code many times | Debugging can be slightly harder if not designed well\r\n",
                "Held centrally alongside data, so clearer governance | `NULL`\r\n",
                "\r\n",
                "### Batching üç´\r\n",
                "Regarding designing a **stored procedure** well, there are several useful commands you can use to create a robust **stored procedure** that is easier to follow and catches errors. Idea is that you can write and run your **stored procedure** in one go, but it is more helpful to run it in batches, so you can also include helpful messages that signal the progress of the **stored procedure**.\r\n",
                "- Think of running your **stored procedure** in batches as equivalent to highlighting your code in chunks and running them separately.\r\n",
                "\r\n",
                "You set-up your batches as follows:\r\n",
                "1. `BEGIN TRANSACTION` - signals to SQL server the start point of a batch of T-SQL statements\r\n",
                "1. `GO` - signals to SQL server to run a set of T-SQL statements\r\n",
                "1. `COMMIT` - signals to SQL server to make permanent changes in a table based on a batch of code\r\n",
                "1. `ROLLBACK` - signals to SQL to cancel **all** changes previously executed in a batch of code\r\n",
                "\r\n",
                "### Error trapping üíî\r\n",
                "Using the `TRY ... CATCH` statement, you can specify what happens when you capture and output errors. The structure of it is as follows:\r\n",
                "```\r\n",
                "BEGIN TRY\r\n",
                "    <sql_statement>\r\n",
                "END TRY\r\n",
                "BEGIN CATCH\r\n",
                "    PRINT ERROR_MESSAGE()\r\n",
                "    PRINT ERROR_NUMBER()\r\n",
                "END CATCH\r\n",
                "GO\r\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "1d9dbf7d-baf4-4088-842f-cf94c2e793ff"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- error trapping\r\n",
                "BEGIN TRY\r\n",
                "    -- generate a divide-by-zero error\r\n",
                "    SELECT 1/0;\r\n",
                "END TRY\r\n",
                "BEGIN CATCH\r\n",
                "    SELECT \r\n",
                "        [ErrorNumber] = ERROR_NUMBER()\r\n",
                "        ,[ErrorSeverity] = ERROR_SEVERITY()\r\n",
                "        ,[ErrorState] = ERROR_STATE()\r\n",
                "        ,[ErrorProcedure] = ERROR_PROCEDURE()\r\n",
                "        ,[ErrorLine] = ERROR_LINE()\r\n",
                "        ,[ErrorMessage] = ERROR_MESSAGE()\r\n",
                "END CATCH;\r\n",
                "GO"
            ],
            "metadata": {
                "azdata_cell_guid": "b222b91c-00e1-4c24-9d2c-167ef1b8a123"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Combining running batches with error trapping üêÄ\r\n",
                "By combining running batches and error trapping in your **stored procedure** definition, then you are able to create a well-documented, easy-to-follow, robust **stored procedure**. You can avoid saving what happened and instead, move the whole of the `TRY` section of the query back through using `ROLLBACK`, so long as you have not used a `COMMIT` statement.\r\n",
                "```\r\n",
                "BEGIN TRY\r\n",
                "    <sql_statement_one>\r\n",
                "    <sql_statement_two>\r\n",
                "    ...\r\n",
                "END TRY\r\n",
                "BEGIN CATCH\r\n",
                "    IF @@TRANCOUNT >= 1\r\n",
                "    ROLLBACK\r\n",
                "    ... <error_logging>\r\n",
                "END CATCH;\r\n",
                "GO\r\n",
                "```\r\n",
                "\r\n",
                "Typically, it is quite difficult to write a **stored procedure** from first principles or even a template. A better approach is to find an existing **stored procedure** and plagiarise it! Not only does it save you brain power, but it is faster and more error-proof."
            ],
            "metadata": {
                "azdata_cell_guid": "477ab2b6-c30d-49f2-b27f-13ce9ba99c1c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create stored procedure by bringing everything together\r\n",
                "CREATE PROCEDURE [Person].[spr_InsertPersonalDetails]\r\n",
                "    -- add parameters to pass into stored proc here\r\n",
                "    @FirstName AS NVARCHAR(50)\r\n",
                "    ,@LastName AS NVARCHAR(50)\r\n",
                "    ,@Age AS SMALLINT\r\n",
                "    ,@Active AS BIT\r\n",
                "    ,@Salary AS MONEY\r\n",
                "    ,@PPFDeduction AS MONEY\r\n",
                "AS\r\n",
                "BEGIN TRANSACTION\r\n",
                "    BEGIN TRY\r\n",
                "        -- insert into [PersoanlDetails] table\r\n",
                "        INSERT INTO [PersonalDetails] ([FirstName], [LastName], [Age], [Active])\r\n",
                "        VALUES (@FirstName, @LastName, @Age, @Active)\r\n",
                "    GO\r\n",
                "        DECLARE @pdId AS INT\r\n",
                "        SET @pdId = SCOPE_IDENTITY()\r\n",
                "        -- insert into [Accounts] table\r\n",
                "        INSERT INTO [Accounts] ([Salary], [PPFDeduction], [PersonalDetailsId])\r\n",
                "        VALUES(@Salary, @PPFDeduction, @pdId)\r\n",
                "        -- if not error, commit the transaction\r\n",
                "    COMMIT TRANSACTION\r\n",
                "    END TRY\r\n",
                "\r\n",
                "    BEGIN CATCH\r\n",
                "    -- if error, rollback any changes done by any of the SQL statements\r\n",
                "        ROLLBACK TRANSACTION\r\n",
                "    END CATCH\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "b808576a-3d37-4070-8383-7b9e9d8b147c"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7.2. Functions üåÇ\r\n",
                "**Functions:** subprograms commonly used and reused throughout SQL database application for cleaning and manipulating.\r\n",
                "\r\n",
                "Even humble aggregation functions such as `SUM(), AGGREGATE(), ...)` are **functions**.\r\n",
                "\r\n",
                "They are good for the following things:\r\n",
                "- Are written once but used multiple times - saving time and effort in supporting modular programme too. \r\n",
                "- Improve performance and efficiency of the database.\r\n",
                "- Complex progaming logic can be decompoased into a smaller and simpler functions, making it easier to understand and maintain. \r\n",
                "\r\n",
                "### Difference between stored procedures and functions üçäüçé\r\n",
                "Whilst both sound very similar in their operations and constructions, there are subtle differecne between them:\r\n",
                "\r\n",
                "Stored Procedures | Functions\r\n",
                "--- | --- |\r\n",
                "Does not return a value, just `0` or `n` values | Always returns a value\r\n",
                "Can have input **and** output parameters | Only have input parameters for it\r\n",
                "Cannot call them from **Functions** | Can call them from **Stored Procedures**\r\n",
                "Allows `SELECT/INSERT/UPDATE/DELETE` statements | Only allows `SELECT` statement\r\n",
                "`TRY-CATCH` block can handle exceptions | `TRY-CATCH` cannot be used\r\n",
                "Cannot be embedded in `WHERE/HAVING` | Can be embedded in `WHERE/HAVING`\r\n",
                "Returned tables cannot be used in `JOIN` | Retuned tables treated as another rowset and can `JOIN`"
            ],
            "metadata": {
                "azdata_cell_guid": "c45b6c6f-2c72-479b-919a-354c01115aa0"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create a simple stored proc\r\n",
                "CREATE PROCEDURE spr_HelloWorld\r\n",
                "AS\r\n",
                "PRINT 'Hello World'\r\n",
                "\r\n",
                "-- execute stored proc\r\n",
                "EXEC spr_HelloWorld"
            ],
            "metadata": {
                "azdata_cell_guid": "e884571e-e7d8-43cf-856b-5469410880a5"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "-- create a simple function\r\n",
                "CREATE FUNCTION dbo.fn_helloworld()\r\n",
                "RETURNS varchar(20)\r\n",
                "AS \r\n",
                "BEGIN\r\n",
                "\t RETURN 'Hello world'\r\n",
                "END;\r\n",
                "\r\n",
                "GO;\r\n",
                "\r\n",
                "-- call the function\r\n",
                "SELECT dbo.fn_helloworld()"
            ],
            "metadata": {
                "azdata_cell_guid": "0077e124-75c4-4c6b-9def-f652adf0624d"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## ü§º‚Äç‚ôÄÔ∏è EXERCISE: Stored procedures and functions\r\n",
                "**QUESTION:** From running the stored procedure and function defined above, what is the difference in how they are prompted to run?"
            ],
            "metadata": {
                "azdata_cell_guid": "87400370-262f-4f68-b284-d9b246ab3e3d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "321654b5-ba3a-4d18-8c8e-f3aa35f8fe2c"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 8. Database triggers to record activity üìπüì∏üìº\r\n",
                "**Database triggers** are extremely useful in automatically recording acitivty of permanenet changes to a database. It can captures things like:\r\n",
                "- What the change was\r\n",
                "- Who made the change\r\n",
                "- When the change was made\r\n",
                "- Where the change was made in regards to the objects affected\r\n",
                "- How the change was made (displays the code)\r\n",
                "\r\n",
                "As for *Why the change was made*, that's a question that is more easily answered now that you can easily see who made the change and when - it helps you identify the right person to find out, rather than before when you had to scrabble around looking for the right person.\r\n",
                "\r\n",
                "At a basic level, it can also offer a rudimentary form of **version-controlling** from the way the code that caused the change can also be captured. "
            ],
            "metadata": {
                "azdata_cell_guid": "b7200740-bf37-44d0-8037-206f66c4291d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- create schema to assign database activity table in\r\n",
                "IF NOT EXISTS\r\n",
                "(\r\n",
                "\tSELECT [SCHEMA_NAME]\r\n",
                "\tFROM [INFORMATION_SCHEMA].[SCHEMATA]\r\n",
                "\tWHERE [SCHEMA_NAME] = 'AuditDetails'\r\n",
                ")\r\n",
                "\r\n",
                "BEGIN\r\n",
                "EXEC sp_executesql N'CREATE SCHEMA [AuditDetails] AUTHORIZATION [dbo]'\r\n",
                "END;"
            ],
            "metadata": {
                "azdata_cell_guid": "18c2a9d5-b078-40d0-bd3e-01a4278f2913"
            },
            "outputs": [],
            "execution_count": 9
        },
        {
            "cell_type": "code",
            "source": [
                "-- create table to record database activity\r\n",
                "CREATE TABLE [AuditDetails].[DatabaseChangeLog](\r\n",
                "\t[ChangeId] [int] IDENTITY(1,1) NOT NULL\r\n",
                "\t,[ChangeDate] [datetime] NOT NULL \r\n",
                "\t\tCONSTRAINT [DF_ddl_log_ChangeDate]\r\n",
                "\t\t\tDEFAULT (GETDATE())\r\n",
                "\t,[NameUser] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_ddl_log_NameUser]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), USER_NAME(), (0)))\r\n",
                "\t,[NameSecurity] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_DDLChangeLog_NameSecurity]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), SUSER_SNAME(), (0)))\r\n",
                "\t,[NameLogin] [nvarchar](50) NOT NULL\r\n",
                "\t\tCONSTRAINT [DF_DDLChangeLog_NameLogin]   \r\n",
                "            DEFAULT (CONVERT([nvarchar](50), original_login(),(0)))\r\n",
                "\t,[EventType] [nvarchar](100) NULL\r\n",
                "\t,[ObjectName] [nvarchar](100) NULL\r\n",
                "\t,[ObjectType] [nvarchar](100) NULL\r\n",
                "\t,[TsqlCode] [nvarchar](max) NULL\r\n",
                ") ON [PRIMARY] TEXTIMAGE_ON [PRIMARY];"
            ],
            "metadata": {
                "azdata_cell_guid": "a31316d1-b47b-4461-a17d-c4f354676b98"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "-- create and turn on database trigger\r\n",
                "CREATE TRIGGER trg_DatabaseChangeLog ON DATABASE \r\n",
                "    FOR DDL_DATABASE_LEVEL_EVENTS \r\n",
                "AS \r\n",
                "    DECLARE @data XML \r\n",
                "    SET @data = EVENTDATA() \r\n",
                "    IF @data.value('(/EVENT_INSTANCE/EventType)[1]', 'nvarchar(100)') <> 'CREATE_STATISTICS'  \r\n",
                "\t\tINSERT INTO [AuditDetails].[DatabaseChangeLog] \r\n",
                "\t\t( \r\n",
                "\t\t\t[EventType], \r\n",
                "\t\t\t[ObjectName], \r\n",
                "\t\t\t[ObjectType], \r\n",
                "\t\t\t[TsqlCode]\r\n",
                "\t\t) \r\n",
                "\t\tVALUES  \r\n",
                "\t\t( \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/EventType)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/ObjectName)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/ObjectType)[1]', 'nvarchar(100)'), \r\n",
                "\t\t\t@data.value('(/EVENT_INSTANCE/TSQLCommand)[1]', 'nvarchar(max)') \r\n",
                "\t\t);\r\n",
                "\r\n",
                "-- turn-on trigger\r\n",
                "ENABLE TRIGGER [trg_DatabaseChangeLog] ON DATABASE;"
            ],
            "metadata": {
                "azdata_cell_guid": "f132599d-8a93-446a-bbf2-f47d06446837"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "-- create View to pull in schema name so can better identify tables\r\n",
                "CREATE VIEW [AuditDetails].[vw_DatabaseChangeLog]\r\n",
                "AS \r\n",
                "(\r\n",
                "    SELECT changelog.[ChangeId]\r\n",
                "        ,changelog.[ChangeDate]\r\n",
                "        ,changelog.[NameUser]\r\n",
                "        ,changelog.[NameSecurity]\r\n",
                "        ,changelog.[NameLogin]\r\n",
                "        ,changelog.[EventType]\r\n",
                "        ,[SchemaId] = admintable.[schema_id]\r\n",
                "        ,[SchemaName] = OBJECT_SCHEMA_NAME(admintable.[object_id])\r\n",
                "        ,[ObjectId] = admintable.[object_id]\r\n",
                "        ,changelog.[ObjectName]\r\n",
                "        ,[ObjectType] = admintable.[type_desc]\r\n",
                "        ,changelog.[TsqlCode]\r\n",
                "    FROM [AuditDetails].[DatabaseChangeLog] AS changelog\r\n",
                "    LEFT JOIN [sys].[all_objects] AS admintable\r\n",
                "        ON changelog.[objectName] = admintable.[name]\r\n",
                "    -- Keep only 'genuine'/real-people SQL users\r\n",
                "    WHERE changelog.[NameUser] != 'dbo'\r\n",
                ");"
            ],
            "metadata": {
                "azdata_cell_guid": "40e880f9-a571-4c63-85c0-fb2c8919bea5"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "-- see what activity has been recorded\r\n",
                "SELECT TOP 100 *\r\n",
                "FROM [AuditDetails].[vw_DatabaseChangeLog];"
            ],
            "metadata": {
                "azdata_cell_guid": "f13ead4c-821b-4bb7-9c39-907e326a8663"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üî≠ EXERCISE: Querying from a big-brother table\r\n",
                "**QUESTION:** In the `[AuditDetails].[vw_DatabaseChangeLog]` table, can you query it to look for changes that you have done to the database?"
            ],
            "metadata": {
                "azdata_cell_guid": "44b1f75d-cfa4-4caf-af49-9835a2054f00"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "-- please write your answer below"
            ],
            "metadata": {
                "azdata_cell_guid": "0e74484b-f312-450e-9643-d4ba0830479c"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 9. Version-controlling your database ‚ú®üåà\r\n",
                "Originating from the software development world, effectively tracking and commenting what and why a change was made to your code, whilst retaining the ability to easily revert to an old state of your code, **version-controlling** is now a core principle in any general best practice approaches to writing code.\r\n",
                "\r\n",
                "Whereas in *(8.)* offers a rudimentary approach to **version-control** in the way it captures the actual SQL code used to make the change, and has accompaying information on who made the change and when it was made, it does not realise the full vision of **version-control** - namely, it is the ability to revert to older states easily and working collaboratively.\r\n",
                "\r\n",
                "> **PRIOR KNOWLEDGE RQUIRED:** This section assumes a knowledge of Git, especially its terminology.\r\n",
                "\r\n",
                "At the first-level, you can save a copy/script of each object you create in SQL and *git* version-control those scripts, though this can quickly get tedious when you start having around 15 or more tables, Views, stored procedures, functions database triggers, constraints to manage.\r\n",
                "\r\n",
                "Enter the second-level, where through **Visual Studio**, you can easily take a copy of all the objects in your database, save them on to a drive and **version control** via **Git**, ensuring you `push` and `pull()` from the remote repo on GitHub or Azure DevOps.\r\n",
                "\r\n",
                "Additional guidance is available on Github [here](https://github.com/avisionh/SQL-Titbits/wiki/User-Guide:-SQL-x-Git-Version-Control)."
            ],
            "metadata": {
                "azdata_cell_guid": "1137155a-2062-499a-acc0-2f5fcb94c1f9"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ed2e5d34-5e33-490f-abe7-c1df48ebd7bf"
            }
        }
    ]
}